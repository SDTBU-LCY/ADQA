# ADQA: Knowledge Graph-Enhanced Multimodal Question Answering Model for System Architectural Diagrams
---
Current visual question-answering models for structured images primarily focus on flowcharts and structural diagrams, resulting in limited capability in comprehension system architectural diagrams with complex semantics. To address this limitation, we propose ADQA, a novel model specifically designed for visual question-answering tasks on system architectural diagrams. The model first extracts semantic information from the diagrams and organizes it into a Knowledge Graph (KG). Subsequently, a Large Language Model (LLM) performs Retrieval-Augmented Generation (RAG) over the KG to generate more accurate responses to user queries. ADQA comprises two core modules, each designed to extract specific types of semantic information from system architectural diagrams. The outputs of these modules are integrated to construct a comprehensive and semantically enriched KG. Furthermore, we introduce a new dataset, ADS, consisting of 500 system architectural diagram images and 2,781 question-answer pairs. We evaluated ADQAâ€™s question-answering performance against existing Multimodal Large Language Models (MLLMs) using the ADS dataset. Experimental results demonstrate the effectiveness, robustness, and interpretability of the ADQA model. Notably, ADQA achieved a 7.41\% improvement in question-answering accuracy over the current state-of-the-art (SOTA) model. The complete dataset and the partial source code are publicly available at https://github.com/SDTBU-LCY/ADQA.
---
The code is being organized.
